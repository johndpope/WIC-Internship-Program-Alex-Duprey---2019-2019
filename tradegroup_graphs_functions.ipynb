{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###This code can be used to fill in history if needed to repeat, see tradgroup_graphs_update file for just appening new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "from contextlib import closing\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import MySQLdb\n",
    "import pymssql\n",
    "import dfutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = 'wic'\n",
    "WIC_DB_HOST = 'wic-risk-database.cwi02trt7ww1.us-east-1.rds.amazonaws.com'\n",
    "DB_USER = 'aduprey'\n",
    "DB_PASSWORD = 'aduprey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_execute(query, commit=False):\n",
    "    '''\n",
    "    Executes the search query in Northpoint\n",
    "    '''\n",
    "    \n",
    "    with closing(pymssql.connect(host='10.16.1.16', user='readonly_user', password='readonly_user',\n",
    "                                 database='PnLAppDb')) as np_pnl_conn:\n",
    "        with closing(np_pnl_conn.cursor()) as np_pnl_cursor:\n",
    "            np_pnl_cursor.execute(query)\n",
    "            if commit:\n",
    "                np_pnl_conn.commit()\n",
    "                return\n",
    "\n",
    "            fetched_res = np_pnl_cursor.fetchall()  # fetch (and discard) remaining rows\\\n",
    "            return fetched_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tradar_optimized_execute(query, commit=False):\n",
    "    try:\n",
    "        with closing(pymssql.connect(host='NYDC-WTRTRD01', user='paz', password='Welcome2',\n",
    "                                     database='TradarBE')) as trdr_pnl_conn:\n",
    "            with closing(trdr_pnl_conn.cursor()) as trdr_pnl_cursor:\n",
    "                trdr_pnl_cursor.execute(query)\n",
    "                if commit:\n",
    "                    trdr_pnl_conn.commit()\n",
    "                    return\n",
    "\n",
    "                fetched_res = trdr_pnl_cursor.fetchall()  # fetch (and discard) remaining rows\\\n",
    "                return fetched_res\n",
    "    except Exception as e:\n",
    "        print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_calculated_values_history_max_date():  # done\n",
    "    query = \"SELECT MAX(PCVH.TradeDate) FROM [PnLAppDb].[dbo].[PositionCalculatedValuesHistory] AS PCVH \"\n",
    "    results = optimized_execute(query)\n",
    "    if len(results) == 0:\n",
    "        return None\n",
    "\n",
    "    return results[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_calculated_values_history(start_date_yyyy_mm_dd=None, end_date_yyyy_mm_dd=None,\n",
    "                                           limit_to_tradegroups=[], is_tg_names_in_tradar_format=False,\n",
    "                                           fund_code=None, NP_qty_rollup=True):\n",
    "    if start_date_yyyy_mm_dd is None or end_date_yyyy_mm_dd is None:\n",
    "        start_date_yyyy_mm_dd = '2016-01-01'\n",
    "        end_date_yyyy_mm_dd = get_position_calculated_values_history_max_date()\n",
    "    tg_filter_clause = \"\"\n",
    "    if len([tg for tg in limit_to_tradegroups if tg is not None]) > 0:\n",
    "        tg_filter_clause = \" AND PCVH.TradeGroup IN (\" + \",\".join([(\"'\" + tg + \"'\") \n",
    "                                                                   for tg in limit_to_tradegroups \n",
    "                                                                   if tg is not None]) + \") \"\n",
    "        if is_tg_names_in_tradar_format: \n",
    "            tg_filter_clause = tg_filter_clause.replace('PCVH.TradeGroup', 'SUBSTRING(PCVH.TradeGroup,0,21)')\n",
    "            \n",
    "    fund_code_filtuer_clause = \" \" if fund_code is None else \" AND PCVH.FundCode = '\" + fund_code + \"' \"\n",
    "    # region query\n",
    "    # New Fund by added bv Kshitij \"WATER ISLAND MERGER ARBITRAGE INSTITUTIONAL\":\"MACO\"\n",
    "    query = \"SELECT \" \\\n",
    "            \"PCVH.TradeDate, \" \\\n",
    "            \"ISNULL(PCVH.FundCode, \" \\\n",
    "            \"CASE F.FundName \" \\\n",
    "            \"WHEN 'Columbia' THEN 'CAM' \" \\\n",
    "            \"WHEN 'Litman Gregory' THEN 'LG' \" \\\n",
    "            \"WHEN 'The Arbitrage Credit Opportunities Fund' THEN 'TACO' \" \\\n",
    "            \"WHEN 'The Arbitrage Event-Driven Fund' THEN 'AED' \" \\\n",
    "            \"WHEN 'The Arbitrage Fund' THEN 'ARB' \" \\\n",
    "            \"WHEN 'TransAmerica' THEN 'TAF' \" \\\n",
    "            \"WHEN 'WIC Arbitrage Partners' THEN 'WIC' \" \\\n",
    "            \"WHEN 'The Arbitrage Tactical Equity Fund' THEN 'TAQ' \" \\\n",
    "            \"WHEN 'Water Island Event-Driven Fund' THEN 'WED' \" \\\n",
    "            \"WHEN 'Water Island Capital Lev Arb Fund' THEN 'WED' \" \\\n",
    "            \"WHEN 'WATER ISLAND MERGER ARBITRAGE INSTITUTIONAL' THEN 'MACO' \" \\\n",
    "            \"WHEN 'Morningstar Alternatives Fund' THEN 'MALT' \" \\\n",
    "            \"END \" \\\n",
    "            \") AS FundCode, \" \\\n",
    "            \"SPT_TRDGRP.SecName AS TradeGroup, \" \\\n",
    "            \"SPT_TRDGRP.SecName AS TradeGroup_Tradar_Name, \" \\\n",
    "            \"PCVH.[Marketing GROUP] AS Sleeve,   \" \\\n",
    "            \"ISNULL(PCVH.[Bucket],'NA') AS Bucket, \" \\\n",
    "            \"PCVH.TradeGroupId, \" \\\n",
    "            \"SPT.Ticker, \" \\\n",
    "            \"SPT.SecType, \" \\\n",
    "            \"ISNULL(SPT.MarketCapCategory, 'N/A') AS MarketCapCategory, \" \\\n",
    "            \"PCVH.SecurityID, \" \\\n",
    "            \"PCVH.DealTermsCash, \" \\\n",
    "            \"PCVH.DealTermsStock, \" \\\n",
    "            \"PCVH.DealValue, \" \\\n",
    "            \"PCVH.DealClosingDate, \" \\\n",
    "            \"CASE \" \\\n",
    "            \"WHEN SPT.SecType = 'FxFwd' THEN 0.0 \" \\\n",
    "            \"WHEN SPT.SecType <> 'FxFwd' AND PCVH.[Marketing GROUP] = 'Equity Special Situations'  THEN 1.0 \" \\\n",
    "            \"WHEN SPT.SecType <> 'FxFwd' AND PCVH.[Marketing GROUP] = 'Opportunistic'  THEN 1.0 \" \\\n",
    "            \"WHEN SPT.SecType <> 'FxFwd' AND PCVH.[Marketing GROUP] = 'Merger Arbitrage'  THEN \" \\\n",
    "            \"CASE WHEN ISNULL(PCVH.AlphaHedge,'NA') IN ('Alpha','Alpha Hedge') THEN \" \\\n",
    "            \"CASE PCVH.DealValue WHEN 0 THEN 0.0 ELSE PCVH.DealTermsStock/PCVH.DealValue END \" \\\n",
    "            \"ELSE 1.0 END \" \\\n",
    "            \"WHEN SPT.SecType <> 'FxFwd' AND PCVH.[Marketing GROUP] = 'Credit Opportunities'  THEN \" \\\n",
    "            \"CASE WHEN SPT.SecType IN ('EQ','ExchOpt') THEN 1.0 ELSE 0.0 END \" \\\n",
    "            \"ELSE NULL END \" \\\n",
    "            \"AS [Equity Risk Factor], \" \\\n",
    "            \"PCVH.DV_01, \" \\\n",
    "            \"PCVH.CR_01, \" \\\n",
    "            \"PCVH.Adj_CR_01, \" \\\n",
    "            \"ISNULL(SPT.UltimateCountry,'N/A') AS UltimateCountry, \" \\\n",
    "            \"ISNULL(PCVH.AlphaHedge,'NA') AS AlphaHedge, \" \\\n",
    "            \"SUM(PCVH.ExposureLong_USD) AS Exposure_Long, \" \\\n",
    "            \"SUM(PCVH.ExposureShort_USD) AS Exposure_Short, \" \\\n",
    "            \"SUM(PCVH.ExposureLong_USD+PCVH.ExposureShort_USD) AS Exposure_Net, \" \\\n",
    "            \"CASE WHEN NAV.NAV = 0 THEN NULL \" \\\n",
    "            \"ELSE 100.0*(SUM(PCVH.ExposureLong_USD+PCVH.ExposureShort_USD)/NAV.NAV) END \" \\\n",
    "            \"AS [Exposure_Net(%)], \" \\\n",
    "            \"SUM(PCVH.MktValLong_USD+PCVH.MktValShort_USD) AS NetMktVal, \" \\\n",
    "            \"CASE WHEN ISNULL(PCVH.AlphaHedge,'NA') IN ('Alpha','Alpha Hedge') \" \\\n",
    "            \"THEN ABS(SUM(PCVH.MktValLong_USD+PCVH.MktValShort_USD)) ELSE NULL END AS Capital, \" \\\n",
    "            \"CASE WHEN ISNULL(PCVH.AlphaHedge,'NA') IN ('Alpha','Alpha Hedge') \" \\\n",
    "            \"THEN 100.0*(ABS(SUM(PCVH.MktValLong_USD+PCVH.MktValShort_USD))/NAV.NAV) ELSE NULL \" \\\n",
    "            \"END AS [Capital % of NAV], \" \\\n",
    "            \"100.0*SUM(PCVH.Base_Case_NAV_Impact) AS BaseCaseNavImpact, \" \\\n",
    "            \"100.0*SUM(PCVH.Outlier_NAV_Impact) AS OutlierNavImpact, \" \\\n",
    "            \"SUM(PCVH.Qty) AS QTY, \" \\\n",
    "            \"ISNULL(PCVH.TradeGroupLongShortFlag,'NA') AS LongShort, \" \\\n",
    "            \"ISNULL(SPT.GICSSectorName,'NA') AS Sector, \" \\\n",
    "            \"ISNULL(SPT.GICSIndustryName,'NA') AS Industry, \" \\\n",
    "            \"NAV.NAV \" \\\n",
    "            \"FROM [PnLAppDb].[dbo].[PositionCalculatedValuesHistory] AS PCVH \" \\\n",
    "            \"INNER JOIN PnLAppDb.dbo.Funds AS F ON PCVH.Portfolio = F.FundID \" \\\n",
    "            \"INNER JOIN SecurityMaster.dbo.SecurityPivotTable AS SPT ON PCVH.SecurityID = SPT.ID \" \\\n",
    "            \"INNER JOIN SecurityMaster.dbo.SecurityPivotTable AS SPT_TRDGRP ON PCVH.TradeGroupId = SPT_TRDGRP.ID \" \\\n",
    "            \"LEFT OUTER JOIN PnLAppDb.pnl.DailyNAV AS NAV ON PCVH.Portfolio = NAV.FundId \" \\\n",
    "            \"AND PCVH.TradeDate = NAV.[DATE] \" \\\n",
    "            \"WHERE  TradeDate >= '\" + start_date_yyyy_mm_dd + \"' AND TradeDate <= '\" + end_date_yyyy_mm_dd + \"' \" \\\n",
    "            + tg_filter_clause + \\\n",
    "            fund_code_filtuer_clause + \\\n",
    "            \"GROUP BY \" \\\n",
    "            \"F.FundName, PCVH.FundCode,PCVH.TradeDate, PCVH.[Marketing GROUP], SPT_TRDGRP.SecName, \" \\\n",
    "            \"PCVH.TradeGroupId, SPT.Ticker, SPT.BloombergGlobalId, SPT.BloombergGID, \" \\\n",
    "            \"SPT.SecType, ISNULL(SPT.MarketCapCategory, 'N/A'), \" \\\n",
    "            \"PCVH.SecurityId, SPT.UltimateCountry, \" \\\n",
    "            \"ISNULL(PCVH.AlphaHedge,'NA'),PCVH.TradeGroupLongShortFlag, ISNULL(SPT.GICSSectorName,'NA'), \" \\\n",
    "            \"ISNULL(SPT.GICSIndustryName,'NA'), ISNULL(PCVH.TradeGroupCatalystRating, 'NA'), \" \\\n",
    "            \"ISNULL(PCVH.[Bucket],'NA'), PCVH.DealTermsCash, PCVH.DealTermsStock, \" \\\n",
    "            \"PCVH.DealValue, PCVH.DealClosingDate, \" \\\n",
    "            \"PCVH.DV_01, PCVH.CR_01, PCVH.Adj_CR_01, NAV.NAV, PCVH.Analyst \" \\\n",
    "            \"ORDER BY PCVH.TradeDate \"\n",
    "    # endregion\n",
    "    results = optimized_execute(query)\n",
    "    df = pd.DataFrame(results, columns=[\"Date\", \"FundCode\", \"TradeGroup\", \"TradeGroup_Tradar_Name\", \"Sleeve\",\n",
    "                                        \"Bucket\", \"TradeGroupId\", \"Ticker\", \"SecType\", \"MarketCapCategory\",\n",
    "                                        \"SecurityId\", \"DealTermsCash\", \"DealTermsStock\", \"DealValue\", \n",
    "                                        \"DealClosingDate\", \"Equity_Risk_Factor\", \"DV01\", \"CR01\", \"Adj_CR01\",\n",
    "                                        \"UltimateCountry\", \"AlphaHedge\", \"Exposure_Long\", \"Exposure_Short\",\n",
    "                                        \"Exposure_Net\", \"Exposure_Net(%)\", \"NetMktVal\", \"Capital($)\", \n",
    "                                        \"Capital(%)\", \"BaseCaseNavImpact\", \"OutlierNavImpact\", \"Qty\", \n",
    "                                        \"LongShort\", \"Sector\", \"Industry\", \"Fund_NAV\"])\n",
    "\n",
    "    float_cols = ['NetMktVal', 'Capital($)', 'Capital(%)', 'Exposure_Net', 'Exposure_Net(%)', 'BaseCaseNavImpact']\n",
    "    df[float_cols] = df[float_cols].astype(float)\n",
    "    df['Equity_Risk_Exp'] = df['Equity_Risk_Factor'].astype(float)*df['Exposure_Net'].astype(float)\n",
    "    df[['DV01', 'CR01', 'Adj_CR01']] = df[['DV01', 'CR01', 'Adj_CR01']].fillna(0).astype(float)\n",
    "    df[\"Date\"] = df[\"Date\"].apply(lambda x: pd.to_datetime(x))\n",
    "    df[\"DealClosingDate\"] = df[\"DealClosingDate\"].apply(lambda x: pd.to_datetime(x))\n",
    "\n",
    "    as_of_dt = datetime.datetime.strptime(end_date_yyyy_mm_dd, '%Y-%m-%d')\n",
    "\n",
    "    def duration_calc(days):\n",
    "        if days <= 90:\n",
    "            return '0M-3M'\n",
    "        if days <= 180:\n",
    "            return '3M-6M'\n",
    "        if days <= 365:\n",
    "            return '6M-12M'\n",
    "        return 'Yr+'\n",
    "\n",
    "    df[\"DealDuration\"] = df[\"DealClosingDate\"].apply(lambda x: None if pd.isnull(x) else\n",
    "                                                     duration_calc((as_of_dt - pd.to_datetime(x)).days))\n",
    "\n",
    "    # region ADJUSTING FOR POSTED TRADES AFTER TRADE DATE - AFFECTING QTY ONLY\n",
    "    # adjust for end_date_yyyy_mm_dd - take trades with tradedate = end_date_yyyy_mm_dd and posted_date\n",
    "    #AFTER end_date_yyyy_mm_dd\n",
    "    # adjust the Qty into the pcvh_df\n",
    "    if NP_qty_rollup:\n",
    "        qty_adjust_query = \"SELECT \" \\\n",
    "                            \"A.TradeDate AS [DATE], \" \\\n",
    "                            \"CASE A.Fund \" \\\n",
    "                            \"WHEN 'Columbia' THEN 'CAM' \" \\\n",
    "                            \"WHEN 'Litman Gregory' THEN 'LG' \" \\\n",
    "                            \"WHEN 'The Arbitrage Credit Opportunities Fund' THEN 'TACO' \" \\\n",
    "                            \"WHEN 'The Arbitrage Event-Driven Fund' THEN 'AED' \" \\\n",
    "                            \"WHEN 'The Arbitrage Fund' THEN 'ARB' \" \\\n",
    "                            \"WHEN 'TransAmerica' THEN 'TAF' \" \\\n",
    "                            \"WHEN 'WIC Arbitrage Partners' THEN 'WIC' \" \\\n",
    "                            \"WHEN 'The Arbitrage Tactical Equity Fund' THEN 'TAQ' \" \\\n",
    "                            \"WHEN 'Water Island Event-Driven Fund' THEN 'WED' \" \\\n",
    "                            \"WHEN 'Water Island Capital Lev Arb Fund' THEN 'LEV' \" \\\n",
    "                            \"WHEN 'WATER ISLAND MERGER ARBITRAGE INSTITUTIONAL COMMINGLED MASTER FUND LP' THEN 'MACO' \" \\\n",
    "                            \"WHEN 'Morningstar Alternatives Fund' THEN 'MALT' \" \\\n",
    "                            \"END AS FundCode, \" \\\n",
    "                            \"A.TradeGroupId, \" \\\n",
    "                            \"A.SecurityId, \" \\\n",
    "                            \"SUM((CASE SPT.SecType WHEN 'ExchOpt' THEN 100.0 ELSE 1.0 END)*A.Shares) AS Qty \" \\\n",
    "                            \"FROM \" \\\n",
    "                            \"[PnLAppDb].[dbo].[vTradesFlatView] AS A \" \\\n",
    "                            \"INNER JOIN SecurityMaster.dbo.SecurityPivotTable AS SPT ON A.SecurityId = SPT.ID \" \\\n",
    "                            \"WHERE PostedDate >= DATEADD(DAY,1,TradeDate) AND TradeDate >= '\" \\\n",
    "                            + start_date_yyyy_mm_dd + \"' \" \\\n",
    "                            \"GROUP BY A.TradeDate, A.SecurityId, A.Ticker, A.Fund, A.TradeGroupId, SPT.SecType \"\n",
    "        results = optimized_execute(qty_adjust_query)\n",
    "        qty_adjust_df = pd.DataFrame(results, columns=['Date', 'FundCode', 'TradeGroupId', 'SecurityId', 'Qty_adj'])\n",
    "        qty_adjust_df[['TradeGroupId', 'SecurityId', 'Qty_adj']] = qty_adjust_df[['TradeGroupId',\n",
    "                                                                                  'SecurityId', 'Qty_adj']].astype(float)\n",
    "        qty_adjust_df['Date'] = qty_adjust_df['Date'].apply(lambda x: pd.to_datetime(x))\n",
    "\n",
    "        df[['TradeGroupId', 'SecurityId', 'Qty']] = df[['TradeGroupId', 'SecurityId', 'Qty']].astype(float)\n",
    "        df = pd.merge(df, qty_adjust_df, how='left', on=['Date', 'FundCode', 'TradeGroupId', 'SecurityId'])\n",
    "        df['Qty'] = df['Qty'] + df['Qty_adj'].fillna(0)\n",
    "        del df['Qty_adj']\n",
    "    # endregion\n",
    "    print('PCVH retrieval completed....')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NAV_df():\n",
    "    query = \"SELECT A.[DATE],A.NAV, \" \\\n",
    "            \"CASE B.FundName \" \\\n",
    "            \"WHEN 'Columbia' THEN 'CAM' \" \\\n",
    "            \"WHEN 'Litman Gregory' THEN 'LG' \" \\\n",
    "            \"WHEN 'The Arbitrage Credit Opportunities Fund' THEN 'TACO' \" \\\n",
    "            \"WHEN 'The Arbitrage Event-Driven Fund' THEN 'AED' \" \\\n",
    "            \"WHEN 'The Arbitrage Fund' THEN 'ARB' \" \\\n",
    "            \"WHEN 'TransAmerica' THEN 'TAF' \" \\\n",
    "            \"WHEN 'WIC Arbitrage Partners' THEN 'WIC' \" \\\n",
    "            \"WHEN 'The Arbitrage Tactical Equity Fund' THEN 'TAQ' \" \\\n",
    "            \"WHEN 'Water Island Event-Driven Fund' THEN 'WED' \" \\\n",
    "            \"WHEN 'Water Island Capital Lev Arb Fund' THEN 'LEV' \" \\\n",
    "            \"WHEN 'WATER ISLAND MERGER ARBITRAGE INSTITUTIONAL' THEN 'MACO' \" \\\n",
    "            \"WHEN 'Morningstar Alternatives Fund' THEN 'MALT' \" \\\n",
    "            \"END AS FundCode \" \\\n",
    "            \"FROM PnLAppDb.pnl.DailyNAV AS A \" \\\n",
    "            \"INNER JOIN PnLAppDb.dbo.Funds AS B ON A.FundId = B.FundID \" \\\n",
    "            \"ORDER BY A.[DATE]\"\n",
    "\n",
    "    results = optimized_execute(query)\n",
    "    df = pd.DataFrame(results, columns=[\"Date\", \"NAV\", \"FundCode\"])\n",
    "    df.set_index(pd.DatetimeIndex(df['Date']), inplace=True)\n",
    "    df.index.name = 'Date'\n",
    "    df = df.sort_index()\n",
    "    df['NAV'] = df['NAV'].astype(float)\n",
    "    #idx = pd.date_range(df['Date'].min(), df['Date'].max())\n",
    "    #df = df.reindex(idx, fill_value=np.nan)\n",
    "    del df['Date']\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df.rename(columns={\"index\": \"Date\"}, inplace=True)\n",
    "    df.index.name = 'Date'\n",
    "    df.ffill(inplace=True)\n",
    "    df.set_index(pd.DatetimeIndex(df['Date']), inplace=True)\n",
    "    df['Date'] = df['Date'].apply(lambda x: pd.to_datetime(x))\n",
    "    # df.reset_index(inplace=True)\n",
    "    df = df.reset_index(level=0, drop=True).reset_index()  # Added by Kshitij\n",
    "    del df['index']\n",
    "    return df[df['Date'] <= (datetime.datetime.today() - datetime.timedelta(days=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spread_history():\n",
    "    query = \"SELECT DISTINCT \" \\\n",
    "            \"PCVH.TradeDate, \" \\\n",
    "            \"SPT_TRDGRP.SecName AS TradeGroup, \" \\\n",
    "            \"SPT_TRDGRP.SecName AS TradeGroup_TradarName, \" \\\n",
    "            \"PCVH.TradeGroupId, \" \\\n",
    "            \"PCVH.AllInSpread, \" \\\n",
    "            \"PCVH.DealValue, \" \\\n",
    "            \"100.0*(PCVH.AllInSpread/PCVH.DealValue) AS spread \" \\\n",
    "            \"FROM PnLAppDb.dbo.PositionCalculatedValuesHistory AS PCVH \" \\\n",
    "            \"INNER JOIN SecurityMaster.dbo.SecurityPivotTable AS SPT_TRDGRP ON PCVH.TradeGroupId = SPT_TRDGRP.ID \" \\\n",
    "            \"INNER JOIN SecurityMaster.dbo.SecurityPivotTable AS SPT_TARGET ON PCVH.SecurityID= SPT_TARGET.ID \" \\\n",
    "            \"WHERE  SPT_TRDGRP.TargetTickers LIKE ('%'+SPT_TARGET.Ticker+'%') AND PCVH.TradeDate >= '2015-11-09' \" \\\n",
    "            \"AND PCVH.ConsolidatedMarketingGroup = 'Merger Arbitrage' AND PCVH.DealValue <> 0 \" \\\n",
    "            \"AND PCVH.AllInSpread IS NOT NULL \" \\\n",
    "            \"ORDER BY TradeDate \"\n",
    "    \n",
    "    results = optimized_execute(query)\n",
    "    columns = [\"Date\", \"TradeGroup\", \"TradeGroup_TradarName\", \"TradeGroupId\", \"AllInSpread\", \"DealValue\", \"Spread(%)\"]\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "    df[\"Date\"] = df[\"Date\"].apply(lambda x: pd.to_datetime(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wic_optimized_execute(query, commit=False, retrieve_column_names=False, connection_timeout=250, extra_values=None):\n",
    "    with closing(MySQLdb.connect(host=WIC_DB_HOST, user=DB_USER, passwd=DB_PASSWORD, db=DB_NAME)) as wic_cnx:\n",
    "        with closing(wic_cnx.cursor()) as wic_cursor:\n",
    "\n",
    "            if extra_values is not None:\n",
    "                wic_cursor.execute(query, (extra_values,))\n",
    "            else:\n",
    "                wic_cursor.execute(query)\n",
    "            if commit:\n",
    "                wic_cnx.commit()\n",
    "                return\n",
    "            fetched_res = wic_cursor.fetchall()  # fetch (and discard) remaining rows\n",
    "\n",
    "            if retrieve_column_names:\n",
    "                return fetched_res, [i[0] for i in wic_cursor.description]\n",
    "\n",
    "            return fetched_res\n",
    "\n",
    "def get_tradegroups_pnl_cache(fundcode=None, tg=None):\n",
    "    query = \"SELECT `DATE`, Fund, TradeGroup, pnl, cumpnl FROM \" + DB_NAME + \".`tradegroups_pnl_cache`\"\n",
    "    if fundcode is not None and tg is not None:\n",
    "        query += \" WHERE Fund = '\" + fundcode + \"' AND TradeGroup ='\" + tg + \"' \"\n",
    "    elif fundcode is not None:\n",
    "        query += \" WHERE Fund = '\" + fundcode + \"' \"\n",
    "    elif tg is not None:\n",
    "        query += \" WHERE TradeGroup = '\" + tg + \"' \"\n",
    "    else:\n",
    "        query += \"\"\n",
    "        \n",
    "    res = wic_optimized_execute(query)\n",
    "    cols = ['Date', 'Fund', 'TradeGroup', 'Total P&L', 'Cumulative Total P&L']\n",
    "    df = pd.DataFrame(list(res), columns=cols)\n",
    "    df['Date'] = df['Date'].apply(lambda x: pd.to_datetime(x))\n",
    "    df['Total P&L'] = df['Total P&L'].astype(float)\n",
    "    df['Cumulative Total P&L'] = df['Cumulative Total P&L'].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_securities_pnl_by_tradegroup_and_fund(limit_to_tradegroups=[], limit_to_funds=[],\n",
    "                                              is_tg_names_in_tradar_format=False,\n",
    "                                              start_date_yyyymmdd=None, end_date_yyyymmdd=None, rollup_pnl=False):\n",
    "    if start_date_yyyymmdd is None: start_date_yyyymmdd = '20160101'\n",
    "    if end_date_yyyymmdd is None:\n",
    "        now = datetime.datetime.now()\n",
    "        slicer = dfutils.df_slicer()\n",
    "        end_date = slicer.prev_n_business_days(1, now)\n",
    "        end_date_yyyymmdd = end_date.strftime('%Y%m%d')\n",
    "\n",
    "    tg_filter_clause = \"\"\n",
    "    if len([tg for tg in limit_to_tradegroups if tg is not None]) > 0:\n",
    "        tg_filter_clause = \" AND B.strat IN (\" + \",\".join([(\"'\" + tg + \"'\")\n",
    "                                                           for tg in limit_to_tradegroups \n",
    "                                                           if tg is not None]) + \") \"\n",
    "    if is_tg_names_in_tradar_format is True: \n",
    "        tg_filter_clause = tg_filter_clause.replace('B.strat', 'SUBSTRING(B.strat,0,21)')\n",
    "    \n",
    "    fund_code_filter_clause = \"\"\n",
    "    if len([fund for fund in limit_to_funds if fund is not None]) > 0:\n",
    "        fund_code_filter_clause = \" AND F.fund IN (\" + \",\".join([(\"'\" + fund + \"'\")\n",
    "                                                                 for fund in limit_to_funds\n",
    "                                                                 if fund is not None]) + \") \"\n",
    "        \n",
    "    # region rollup query\n",
    "    rollup_sql_query = \"DECLARE @Holidays TABLE ([Date] DATE); \" \\\n",
    "                        \"DECLARE @StartDt INT; \" \\\n",
    "                        \"DECLARE @EndDt INT; \" \\\n",
    "                        \"INSERT INTO @Holidays VALUES \" \\\n",
    "                        \"('2015-01-01'), \" \\\n",
    "                        \"('2015-01-19'), \" \\\n",
    "                        \"('2015-02-16'), \" \\\n",
    "                        \"('2015-04-03'), \" \\\n",
    "                        \"('2015-05-25'), \" \\\n",
    "                        \"('2015-07-03'), \" \\\n",
    "                        \"('2015-09-07'), \" \\\n",
    "                        \"('2015-10-12'), \" \\\n",
    "                        \"('2015-11-11'), \" \\\n",
    "                        \"('2015-11-26'), \" \\\n",
    "                        \"('2015-12-25'), \" \\\n",
    "                        \"('2016-01-01'), \" \\\n",
    "                        \"('2016-01-18'), \" \\\n",
    "                        \"('2016-02-15'), \" \\\n",
    "                        \"('2016-03-25'), \" \\\n",
    "                        \"('2016-05-30'), \" \\\n",
    "                        \"('2016-07-04'), \" \\\n",
    "                        \"('2016-09-05'), \" \\\n",
    "                        \"('2016-11-24'), \" \\\n",
    "                        \"('2016-12-25'), \" \\\n",
    "                        \"('2017-01-02'), \" \\\n",
    "                        \"('2017-01-16'), \" \\\n",
    "                        \"('2017-02-20'), \" \\\n",
    "                        \"('2017-04-14'), \" \\\n",
    "                        \"('2017-05-29'), \" \\\n",
    "                        \"('2017-07-04'), \" \\\n",
    "                        \"('2017-09-04'), \" \\\n",
    "                        \"('2017-10-09'), \" \\\n",
    "                        \"('2017-11-23'), \" \\\n",
    "                        \"('2017-12-25'); \" \\\n",
    "                        \"SET @StartDt = \" + start_date_yyyymmdd + \"; \" \\\n",
    "                        \"SET @EndDt = \" + end_date_yyyymmdd + \"; \" \\\n",
    "                        \"WITH X AS( \" \\\n",
    "                        \"SELECT \" \\\n",
    "                        \"CAST(CONVERT(varchar(8), A.timeKey) AS DATE) as [Date], \" \\\n",
    "                        \"F.fund, \" \\\n",
    "                        \"B.strat AS TradeGroup, \" \\\n",
    "                        \"S.ticker, \" \\\n",
    "                        \"ST.groupingName as sectype, \" \\\n",
    "                        \"SUM(pnlFC) as PNL \" \\\n",
    "                        \"FROM performanceAttributionFact AS A \" \\\n",
    "                        \"INNER JOIN TradeStrat AS B ON A.stratKey = B.stratId \" \\\n",
    "                        \"INNER JOIN TradeFund AS F ON A.fundKey = F.fundId \" \\\n",
    "                        \"INNER JOIN Sec AS S ON S.secId = A.secIdKey \" \\\n",
    "                        \"INNER JOIN SecType AS ST ON ST.sectype = S.sectype \" \\\n",
    "                        \"WHERE A.timeKey >= @StartDt and A.timeKey <= @EndDt \" \\\n",
    "                        + tg_filter_clause + \\\n",
    "                        fund_code_filter_clause + \\\n",
    "                        \"GROUP BY A.timeKey, B.strat, F.fund, S.ticker, ST.groupingName \" \\\n",
    "                        \") \" \\\n",
    "                        \", PNL AS ( \" \\\n",
    "                        \"SELECT \" \\\n",
    "                        \"X.[Date],  \" \\\n",
    "                        \"CASE \" \\\n",
    "                        \"WHEN DATEPART(dw,X.[Date]) IN (7,1) THEN 'WEEKEND' \" \\\n",
    "                        \"WHEN X.[Date] IN (SELECT * FROM @Holidays) THEN 'HOLIDAY' \" \\\n",
    "                        \"ELSE 'BUSINESS DAY' END AS [WeekDay], \" \\\n",
    "                        \"X.Fund, \" \\\n",
    "                        \"X.TradeGroup, \" \\\n",
    "                        \"X.Ticker, \" \\\n",
    "                        \"X.sectype, \" \\\n",
    "                        \"X.PNL \" \\\n",
    "                        \"FROM X \" \\\n",
    "                        \"), \" \\\n",
    "                        \"Position2EndDate AS ( \" \\\n",
    "                        \"SELECT \" \\\n",
    "                        \"X.fund, \" \\\n",
    "                        \"X.TradeGroup, \" \\\n",
    "                        \"X.ticker, \" \\\n",
    "                        \"X.sectype, \" \\\n",
    "                        \"MAX(X.[Date]) AS MaxDate, \" \\\n",
    "                        \"CASE DATEPART(dw,MAX(X.[Date])) \" \\\n",
    "                        \"WHEN 6 THEN DATEADD(DAY,3,MAX(X.[Date])) \" \\\n",
    "                        \"WHEN 7 THEN DATEADD(DAY,2,MAX(X.[Date])) \" \\\n",
    "                        \"ELSE DATEADD(DAY,1,MAX(X.[Date])) END AS NextBusinessDay \" \\\n",
    "                        \"FROM PNL AS X \" \\\n",
    "                        \"GROUP BY X.fund, X.TradeGroup, X.ticker, X.sectype \" \\\n",
    "                        \"), \" \\\n",
    "                        \"Position2EndDate_BD AS ( \" \\\n",
    "                        \"SELECT \" \\\n",
    "                        \"X.fund, \" \\\n",
    "                        \"X.TradeGroup, \" \\\n",
    "                        \"X.ticker, \" \\\n",
    "                        \"X.sectype, \" \\\n",
    "                        \"X.MaxDate, \" \\\n",
    "                        \"CASE \" \\\n",
    "                        \"WHEN NextBusinessDay IN (SELECT * FROM @Holidays) THEN \" \\\n",
    "                        \"CASE DATEPART(dw,NextBusinessDay) \" \\\n",
    "                        \"WHEN 6 THEN DATEADD(DAY,3,NextBusinessDay) \" \\\n",
    "                        \"ELSE DATEADD(DAY,1,NextBusinessDay) END \" \\\n",
    "                        \"ELSE NextBusinessDay \" \\\n",
    "                        \"END AS NextBusinessDay_Holiday_Proof \" \\\n",
    "                        \"FROM Position2EndDate AS X \" \\\n",
    "                        \"), \" \\\n",
    "                        \"PNL_DT AS ( \" \\\n",
    "                        \"SELECT \" \\\n",
    "                        \"A1.[Date], \" \\\n",
    "                        \"A1.[WeekDay],  \" \\\n",
    "                        \"A1.fund, \" \\\n",
    "                        \"A1.TradeGroup, \" \\\n",
    "                        \"A1.ticker, \" \\\n",
    "                        \"A1.sectype, \" \\\n",
    "                        \"A1.PNL, \" \\\n",
    "                        \"MAX(A2.[Date]) AS [Last Business Day], \" \\\n",
    "                        \"DATEDIFF(DAY,MAX(A2.[Date]),A1.[Date]) AS [Last BD days diff] \" \\\n",
    "                        \"FROM PNL AS A1 \" \\\n",
    "                        \"LEFT OUTER JOIN PNL AS A2 ON A1.fund = A2.fund and A1.TradeGroup = A2.TradeGroup \" \\\n",
    "                        \"AND A1.ticker = A2.ticker AND A1.sectype = A2.sectype AND A2.[Date] < A1.[Date] \" \\\n",
    "                        \"AND A2.[WeekDay] = 'BUSINESS DAY' \" \\\n",
    "                        \"GROUP BY A1.[Date],A1.[WeekDay],A1.fund, A1.TradeGroup, A1.ticker, A1.sectype, A1.PNL \" \\\n",
    "                        \"), \" \\\n",
    "                        \"T AS ( \" \\\n",
    "                        \"SELECT \" \\\n",
    "                        \"CASE WHEN A1.[Date] = B.MaxDate AND A1.[WeekDay] <> 'BUSINESS DAY' \" \\\n",
    "                        \"THEN B.NextBusinessDay_Holiday_Proof ELSE A1.[Date] END AS [Date], \" \\\n",
    "                        \"CASE WHEN A1.[Date] = B.MaxDate AND A1.[WeekDay] <> 'BUSINESS DAY' \" \\\n",
    "                        \"THEN 'BUSINESS DAY' ELSE A1.[WeekDay] END AS [WeekDay], \" \\\n",
    "                        \"A1.fund, \" \\\n",
    "                        \"A1.TradeGroup, \" \\\n",
    "                        \"A1.ticker, \" \\\n",
    "                        \"A1.sectype, \" \\\n",
    "                        \"A1.[Last Business Day], \" \\\n",
    "                        \"A1.PNL, \" \\\n",
    "                        \"ISNULL(SUM(A2.PNL),0) AS ROLLED_UP_PNL, \" \\\n",
    "                        \"A1.PNL + ISNULL(SUM(A2.PNL),0) AS TOT_PNL,  \" \\\n",
    "                        \"CASE WHEN A1.[Date] = B.MaxDate AND A1.[WeekDay] <> 'BUSINESS DAY' \" \\\n",
    "                        \"THEN 'Closed on non-BD. Shifted to next BD' ELSE NULL END AS 'Notes' \" \\\n",
    "                        \"FROM PNL_DT AS A1 \" \\\n",
    "                        \"LEFT OUTER JOIN PNL_DT AS A2 \" \\\n",
    "                        \"ON A1.fund = A2.fund AND A1.TradeGroup = A2.TradeGroup AND A1.ticker = A2.ticker \" \\\n",
    "                        \"AND A1.sectype = A2.sectype AND \" \\\n",
    "                        \"(A2.[Date] < A1.[Date] AND (A2.[Date] > A1.[Last Business Day] \" \\\n",
    "                        \"OR A1.[Last Business Day] IS NULL)) \" \\\n",
    "                        \"AND (A1.[Last BD days diff] <= 4 OR A1.[Last BD days diff] IS NULL) \" \\\n",
    "                        \"INNER JOIN Position2EndDate_BD AS B ON A1.fund = B.fund AND A1.TradeGroup = B.TradeGroup \" \\\n",
    "                        \"AND A1.ticker = B.ticker AND A1.sectype = B.sectype \" \\\n",
    "                        \"WHERE A1.[WeekDay] = 'BUSINESS DAY' OR A1.[Date] = B.MaxDate \" \\\n",
    "                        \"GROUP BY A1.[Date],A1.[WeekDay], A1.fund,A1.TradeGroup, A1.ticker, \" \\\n",
    "                        \"A1.sectype, A1.[Last Business Day],A1.[Last BD days diff],A1.PNL, B.MaxDate, \" \\\n",
    "                        \"B.NextBusinessDay_Holiday_Proof \" \\\n",
    "                        \") \" \\\n",
    "                        \"SELECT \" \\\n",
    "                        \"T.[Date],  \" \\\n",
    "                        \"T.fund, \" \\\n",
    "                        \"T.TradeGroup, \" \\\n",
    "                        \"T.ticker, \" \\\n",
    "                        \"T.sectype, \" \\\n",
    "                        \"T.TOT_PNL \" \\\n",
    "                        \"FROM T \" \\\n",
    "                        \"ORDER BY T.fund, T.TradeGroup, T.ticker,T.sectype, T.[Date] \"\n",
    "        \n",
    "    # endregion\n",
    "    # region non-rollup query\n",
    "    # don't take today's pnl - tradar's garbage data\n",
    "    non_rollup_sql_query = \\\n",
    "        \"SELECT \" \\\n",
    "        \"CAST(CONVERT(VARCHAR(8), A.timeKey) AS DATE) AS [DATE], \" \\\n",
    "        \"F.fund, \" \\\n",
    "        \"B.strat AS TradeGroup, \" \\\n",
    "        \"S.ticker, \" \\\n",
    "        \"ST.groupingName AS sectype, \" \\\n",
    "        \"SUM(pnlFC) AS PNL \" \\\n",
    "        \"FROM performanceAttributionFact AS A \" \\\n",
    "        \"INNER JOIN TradeStrat AS B ON A.stratKey = B.stratId \" \\\n",
    "        \"INNER JOIN TradeFund AS F ON A.fundKey = F.fundId \" \\\n",
    "        \"INNER JOIN Sec AS S ON S.secId = A.secIdKey \" \\\n",
    "        \"INNER JOIN SecType AS ST ON ST.sectype = S.sectype \" \\\n",
    "        \"WHERE A.timeKey >= \" + start_date_yyyymmdd + \" AND A.timeKey <= \" \\\n",
    "        + end_date_yyyymmdd + \\\n",
    "        tg_filter_clause + \\\n",
    "        fund_code_filter_clause + \\\n",
    "        \"GROUP BY A.timeKey, B.strat, F.fund,S.ticker,ST.groupingName \" \\\n",
    "        \"ORDER BY F.fund, B.strat,S.ticker,A.timeKey \"\n",
    "    # endregion\n",
    "    query = rollup_sql_query if rollup_pnl else non_rollup_sql_query\n",
    "    cols = ['Date', 'Fund', 'TradeGroup', 'Ticker', 'SecType', 'Total P&L']\n",
    "    try:\n",
    "        query_result = tradar_optimized_execute(query)\n",
    "    except:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    df = pd.DataFrame(query_result, columns=cols)\n",
    "    df['Date'] = df['Date'].apply(lambda x: pd.to_datetime(x))\n",
    "    df['Total P&L'] = df['Total P&L'].astype(float)\n",
    "    df['Cumulative Total P&L'] = None\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_timeseries_df(pnl_df, capital_df, as_of_date=None, calc_stats=True, periods=('MTD', 'QTD', 'YTD',\n",
    "                                                                                      'ITD', '1D', '3D',\n",
    "                                                                                      '5D', '30D')):\n",
    "    empty_stats_df = pd.DataFrame(columns=['Period', 'P&L($)', 'P&L(bps)', 'ROMC(bps)',\n",
    "                                           'ANN. VOL', 'CAPITAL($)', 'CAPITAL CHG(%)'])\n",
    "    empty_stats_df[\"Period\"] = periods\n",
    "    empty_perf_df = pd.DataFrame(columns=pnl_df.columns)\n",
    "    empty_res = (empty_perf_df, empty_stats_df) if calc_stats else empty_perf_df\n",
    "    if len(pnl_df) == 0 or len(pnl_df[pd.isnull(pnl_df['Total P&L'])]) > 0:\n",
    "        return empty_res\n",
    "\n",
    "    # pnl data present. at least calculate p&l cumsum\n",
    "    slicer = dfutils.df_slicer(as_of_date)\n",
    "    empty_stats_df['P&L($)'] = [None if len(sliced_df) == 0 else sliced_df['Total P&L'].sum()\n",
    "                                for (period, sliced_df) in zip(periods, [slicer.slice(pnl_df, p) for p in periods])]\n",
    "\n",
    "    if capital_df is None: \n",
    "        return empty_res\n",
    "    if len(capital_df) == 0 or len(capital_df.columns) <= 1:\n",
    "        return empty_res\n",
    "    if len(capital_df[pd.isnull(capital_df[capital_df.columns[1]])]) > 0:\n",
    "        return empty_res\n",
    "\n",
    "    capital_cln = capital_df.columns[1]\n",
    "    capital_df_cpy = capital_df.copy() # don't change capital_df. work on its copy\n",
    "    capital_df_cpy['Capital'] = capital_df_cpy[capital_cln]\n",
    "    capital_df_cpy['Shifted Capital'] = capital_df_cpy[capital_cln].shift(1)\n",
    "    df = pd.merge(pnl_df, capital_df_cpy, how='left', on=['Date']).sort_values(by='Date') \n",
    "    if pd.isnull(df['Shifted Capital'].iloc[0]): df.loc[0, 'Shifted Capital'] = df['Capital'].iloc[0]\n",
    "    df['Shifted Capital'] = df['Shifted Capital'].apply(lambda x: np.nan if x == 0 else x)\n",
    "    # if pd.isna(df['Shifted Capital'].iloc[1]):\n",
    "    #     print('Updating Shifted capital')\n",
    "    #     df['Shifted Capital'].loc[1] = df['Capital'].loc[1]\n",
    "    #\n",
    "    df['Shifted Forward-Filled Capital'] = df['Shifted Capital'].ffill()\n",
    "    # if pd.isna(df['Shifted Forward-Filled Capital'].iloc[1]):\n",
    "    #     print('Updating Shifted Forward-filled Capital')\n",
    "    #     df['Shifted Forward-Filled Capital'].loc[1] = df['Capital'].loc[1]\n",
    "    try:\n",
    "        if df['Fund'].iloc[0] == 'MACO':   # Temp Fix for MACO\n",
    "            df['Shifted Capital'].iloc[1] = df['Capital'].iloc[1]\n",
    "            df['Shifted Forward-Filled Capital'].iloc[1] = df['Capital'].iloc[1]\n",
    "        # df.drop(df.index[0], inplace=True)\n",
    "        #df.to_csv('TEMPDF-aprl3.csv')\n",
    "\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print('Fund not found in Dataframe')\n",
    "\n",
    "    df[\"P&L bps (ffiled)\"] = 1e4*(df[\"Total P&L\"]/df[\"Shifted Forward-Filled Capital\"]).replace([np.inf,\n",
    "                                                                                                 -np.inf], np.nan)\n",
    "    df[\"Cumulative P&L ($)\"] = df[\"Total P&L\"].cumsum()\n",
    "    df[\"Cumulative P&L bps (ffiled)\"] = 1e4*((1.0+(df[\"P&L bps (ffiled)\"].astype(float)/1e4)).cumprod() -1)\n",
    "    df['Rolling 30D Vol(%)'] = math.sqrt(252)*df['P&L bps (ffiled)'].rolling(window=30).std()/100.0\n",
    "    df['Rolling 60D Vol(%)'] = math.sqrt(252)*df['P&L bps (ffiled)'].rolling(window=60).std()/100.0\n",
    "    df['Rolling 90D Vol(%)'] = math.sqrt(252)*df['P&L bps (ffiled)'].rolling(window=90).std()/100.0\n",
    "    print \"yes\"\n",
    "    if not calc_stats:\n",
    "        return df\n",
    "\n",
    "    # calc stats\n",
    "    stats_df = pd.DataFrame(columns=[\"Period\", 'P&L($)', 'P&L(bps)', 'ROMC(bps)',\n",
    "                                     'ANN. VOL', 'CAPITAL($)', 'CAPITAL CHG(%)'])\n",
    "\n",
    "    for period in periods:\n",
    "        p_df = slicer.slice(df, period)\n",
    "\n",
    "        next_idx = 0 if pd.isnull(stats_df.index.max()) else stats_df.index.max()+1\n",
    "        if len(p_df) == 0:\n",
    "            stats_df.loc[next_idx] = [period, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "            continue\n",
    "\n",
    "        rets = p_df[\"P&L bps (ffiled)\"].astype(float)\n",
    "        vol_pct = math.sqrt(252)*np.std(rets/1e4, ddof=1)*1e2\n",
    "        cumpnl_usd = p_df['Total P&L'].sum()\n",
    "        cumret_bps = ((1+rets/1e4).prod() -1)*1e4\n",
    "        capitals = p_df['Shifted Forward-Filled Capital'].fillna(0).astype(float)\n",
    "        mean_capital = capitals.mean()\n",
    "        if mean_capital == 0:\n",
    "            stats_df.loc[next_idx] = [period, cumpnl_usd, cumret_bps, np.nan, vol_pct, np.nan, np.nan]\n",
    "            continue\n",
    "        #mw_rets = (rets/1e4)*(capitals/mean_capital)\n",
    "        #romwc_bps = ((1+mw_rets).prod() -1)*1e4\n",
    "        romc_bps = 1e4*(cumpnl_usd/mean_capital)\n",
    "        capital_usd = capitals.iloc[-1]\n",
    "        capital_chg_pct = 1e2*((capitals.iloc[-1]/capitals.iloc[0])-1.0) if capitals.iloc[0] != 0 else np.nan\n",
    "        stats_df.loc[next_idx] = [period, cumpnl_usd, cumret_bps, romc_bps, vol_pct,\n",
    "                                  capital_usd, capital_chg_pct]\n",
    "    return df, stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mktval_df(pcvh_df):\n",
    "    float_cols = ['Alpha Exposure', 'AlphaHedge Exposure', 'Hedge Exposure',\n",
    "                  'Alpha NetMktVal', 'AlphaHedge NetMktVal', 'Hedge NetMktVal',\n",
    "                  'Alpha GrossMktVal', 'AlphaHedge GrossMktVal', 'Hedge GrossMktVal',\n",
    "                  'Alpha GrossExp', 'AlphaHedge GrossExp', 'Hedge GrossExp']\n",
    "    calc_cols = ['Bet Exposure', 'Bet NetMktVal','Bet GrossMktVal', 'Total NetExposure',\n",
    "                 'Total NetMktVal', 'Total GrossMktVal']\n",
    "\n",
    "    if len(pcvh_df) == 0: return pd.DataFrame(columns=[\"Date\"]+float_cols+calc_cols)\n",
    "\n",
    "    alpha_pcvh = pcvh_df[pcvh_df['AlphaHedge'] == 'Alpha']\n",
    "    alphahedge_pcvh = pcvh_df[pcvh_df['AlphaHedge'] == 'Alpha Hedge']\n",
    "    hedge_pcvh = pcvh_df[pcvh_df['AlphaHedge'] == 'Hedge']\n",
    "\n",
    "    alpha_net_exp = alpha_pcvh[['Date', 'Exposure_Net']].groupby(\n",
    "        'Date').sum().reset_index().rename(columns={'index':'Date', 'Exposure_Net':'Alpha Exposure'})\n",
    "    alpha_net_mv = alpha_pcvh[['Date', 'NetMktVal']].groupby(\n",
    "        'Date').sum().reset_index().rename(columns={'index':'Date', 'NetMktVal':'Alpha NetMktVal'})\n",
    "    alpha_gross_mv = alpha_pcvh[['Date', 'NetMktVal']].groupby(\n",
    "        'Date').agg(lambda x: sum(abs(x))).reset_index().rename(columns={'index':'Date',\n",
    "                                                                         'NetMktVal':'Alpha GrossMktVal'})\n",
    "    alpha_gross_exp = alpha_pcvh[['Date', 'Exposure_Net']].groupby(\n",
    "        'Date').agg(lambda x: sum(abs(x))).reset_index().rename(columns={'index':'Date',\n",
    "                                                                         'Exposure_Net':'Alpha GrossExp'})\n",
    "\n",
    "    alphahedge_net_exp = alphahedge_pcvh[['Date','Exposure_Net']].groupby(\n",
    "        'Date').sum().reset_index().rename(columns={'index':'Date', 'Exposure_Net':'AlphaHedge Exposure'})\n",
    "    alphahedge_net_mv = alphahedge_pcvh[['Date','NetMktVal']].groupby(\n",
    "        'Date').sum().reset_index().rename(columns={'index':'Date', 'NetMktVal':'AlphaHedge NetMktVal'})\n",
    "    alphahedge_gross_mv = alphahedge_pcvh[['Date','NetMktVal']].groupby(\n",
    "        'Date').agg(lambda x: sum(abs(x))).reset_index().rename(columns={'index':'Date',\n",
    "                                                                         'NetMktVal':'AlphaHedge GrossMktVal'})\n",
    "    alphahedge_gross_exp = alphahedge_pcvh[['Date','Exposure_Net']].groupby(\n",
    "        'Date').agg(lambda x: sum(abs(x))).reset_index().rename(columns={'index':'Date',\n",
    "                                                                         'Exposure_Net':'AlphaHedge GrossExp'})\n",
    "\n",
    "    hedge_net_exp = hedge_pcvh[['Date','Exposure_Net']].groupby(\n",
    "        'Date').sum().reset_index().rename(columns={'index':'Date','Exposure_Net':'Hedge Exposure'})\n",
    "    hedge_net_mv = hedge_pcvh[['Date','NetMktVal']].groupby(\n",
    "        'Date').sum().reset_index().rename(columns={'index':'Date', 'NetMktVal':'Hedge NetMktVal'})\n",
    "    hedge_gross_mv = hedge_pcvh[['Date','NetMktVal']].groupby(\n",
    "        'Date').agg(lambda x: sum(abs(x))).reset_index().rename(columns={'index':'Date',\n",
    "                                                                         'NetMktVal':'Hedge GrossMktVal'})\n",
    "    hedge_gross_exp = hedge_pcvh[['Date','Exposure_Net']].groupby(\n",
    "        'Date').agg(lambda x: sum(abs(x))).reset_index().rename(columns={'index':'Date',\n",
    "                                                                         'Exposure_Net':'Hedge GrossExp'})\n",
    "\n",
    "    mktval_df = pd.merge(alpha_net_exp, alphahedge_net_exp, how='outer', on=['Date']).fillna(0)\n",
    "    mktval_df = pd.merge(mktval_df, hedge_net_exp, how='outer', on=['Date']).fillna(0)\n",
    "    mktval_df = pd.merge(mktval_df, alpha_net_mv, how='outer', on=['Date']).fillna(0)\n",
    "    mktval_df = pd.merge(mktval_df, alphahedge_net_mv, how='outer', on=['Date']).fillna(0)\n",
    "    mktval_df = pd.merge(mktval_df, hedge_net_mv, how='outer', on=['Date']).fillna(0)\n",
    "    mktval_df = pd.merge(mktval_df, alpha_gross_mv, how='outer', on=['Date']).fillna(0)\n",
    "    mktval_df = pd.merge(mktval_df, alphahedge_gross_mv, how='outer', on=['Date']).fillna(0)\n",
    "    mktval_df = pd.merge(mktval_df, hedge_gross_mv, how='outer', on=['Date']).fillna(0)\n",
    "    mktval_df = pd.merge(mktval_df, alpha_gross_exp, how='outer', on=['Date']).fillna(0)\n",
    "    mktval_df = pd.merge(mktval_df, alphahedge_gross_exp, how='outer', on=['Date']).fillna(0)\n",
    "    mktval_df = pd.merge(mktval_df, hedge_gross_exp, how='outer', on=['Date']).fillna(0)\n",
    "\n",
    "    mktval_df[float_cols] = mktval_df[float_cols].astype(float)\n",
    "    mktval_df['Bet Exposure'] = mktval_df['Alpha Exposure']+mktval_df['AlphaHedge Exposure']\n",
    "    mktval_df['Bet NetMktVal'] = mktval_df['Alpha NetMktVal']+mktval_df['AlphaHedge NetMktVal']\n",
    "    mktval_df['Bet GrossMktVal'] = mktval_df['Alpha GrossMktVal']+mktval_df['AlphaHedge GrossMktVal']\n",
    "    mktval_df['Total NetExposure'] = mktval_df['Alpha Exposure']+mktval_df['AlphaHedge Exposure']+mktval_df['Hedge Exposure']\n",
    "    mktval_df['Total GrossExposure'] = mktval_df['Alpha GrossExp']+mktval_df['AlphaHedge GrossExp']+mktval_df['Hedge GrossExp']\n",
    "    mktval_df['Total NetMktVal'] = mktval_df['Alpha NetMktVal']+mktval_df['AlphaHedge NetMktVal']+mktval_df['Hedge NetMktVal']\n",
    "    mktval_df['Total GrossMktVal'] = mktval_df['Alpha GrossMktVal']+mktval_df['AlphaHedge GrossMktVal']+mktval_df['Hedge GrossMktVal']\n",
    "\n",
    "\n",
    "    return mktval_df.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fund_name2code():  # Done\n",
    "    ''' Fund names '''\n",
    "    return {\"Columbia\": \"CAM\",\n",
    "            \"Litman Gregory\": \"LG\",\n",
    "            \"The Arbitrage Credit Opportunities Fund\": \"TACO\",\n",
    "            \"The Arbitrage Event-Driven Fund\": \"AED\",\n",
    "            \"The Arbitrage Fund\": \"ARB\",\n",
    "            \"The Arbitrage Tactical Equity Fund\": \"TAQ\",\n",
    "            \"TransAmerica\": \"TAF\",\n",
    "            \"WIC Arbitrage Partners\": \"WIC\",\n",
    "            \"Water Island Event-Driven Fund\": \"WED\",\n",
    "            \"Water Island Capital Lev Arb Fund\": \"LEV\",\n",
    "            \"WATER ISLAND MERGER ARBITRAGE INSTITUTIONAL\": \"MACO\",\n",
    "            \"Morningstar Alternatives Fund\": \"MALT\"\n",
    "           }\n",
    "\n",
    "def get_fund_code2name():\n",
    "    return {v: k for (k, v) in get_fund_name2code().iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tradegroups_snapshot():\n",
    "    # region query\n",
    "    query = \"SELECT Fund, Sleeve, TradeGroup, Analyst, LongShort, InceptionDate, EndDate, Status,\" \\\n",
    "            \"`Metrics in Bet JSON`,`Metrics in Bet notes JSON`,`Metrics in NAV JSON`,`Metrics in NAV notes JSON` \" \\\n",
    "            \"FROM \" + DB_NAME + \".tradegroups_snapshot2\"\n",
    "    # endregion\n",
    "\n",
    "    res = wic_optimized_execute(query)\n",
    "    cols = ['Fund', 'Sleeve', 'TradeGroup', 'Analyst', 'LongShort', 'InceptionDate', 'EndDate', 'Status',\n",
    "            'Metrics in Bet JSON', 'Metrics in Bet notes JSON', 'Metrics in NAV JSON', 'Metrics in NAV notes JSON']\n",
    "    return pd.DataFrame(list(res), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2row(pivot_col, df):\n",
    "    dfcols = [c for c in df.columns if c != pivot_col]\n",
    "    cols = [colname + '|' + period for (colname, period) in itertools.product(dfcols, df[pivot_col])]\n",
    "    cols2vals = {c:None for c in cols}\n",
    "\n",
    "    for idx in df.index:\n",
    "        row = df.loc[idx]\n",
    "        pivot = row[pivot_col]\n",
    "        for cln in dfcols:\n",
    "            key = cln + '|' + pivot\n",
    "            cols2vals[key] = row[cln]\n",
    "    res = pd.Series()\n",
    "    for cln in cols:\n",
    "        res[cln] = cols2vals[cln]\n",
    "    return res\n",
    "\n",
    "def json2row(json):\n",
    "    df = pd.read_json(json)\n",
    "    return df2row('Period', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tradegroups_attribution_to_fund_nav():\n",
    "    today = datetime.datetime.today()\n",
    "\n",
    "    df = get_tradegroups_snapshot()\n",
    "\n",
    "    df['EndDate'] = df['EndDate'].apply(lambda x: x if x is None else pd.to_datetime(x).strftime('%m/%d/%y'))\n",
    "    df['InceptionDate'] = df['InceptionDate'].apply(lambda x: x if x is None else pd.to_datetime(x).strftime('%m/%d/%y'))\n",
    "    #Do not want tradegroups closed before the start of the current year\n",
    "    #df_reduced = df[df[\"EndDate\"].dt.year >= today.year] #Takes out deals like cash that don't have date- wrong\n",
    "\n",
    "    metrics2include = [('P&L(bps)', 'ITD'), ('P&L($)', 'ITD'),\n",
    "                       ('P&L(bps)', 'YTD'), ('P&L($)', 'YTD'),\n",
    "                       ('P&L(bps)', 'QTD'), ('P&L($)', 'QTD'),\n",
    "                       ('P&L(bps)', 'MTD'), ('P&L($)', 'MTD'),\n",
    "                       ('P&L(bps)', '30D'), ('P&L($)', '30D'),\n",
    "                       ('P&L(bps)', '5D'), ('P&L($)', '5D'),\n",
    "                       ('P&L(bps)', '1D'), ('P&L($)', '1D')]\n",
    "\n",
    "    metric2display_name = {'P&L(bps)': '', 'P&L($)': ''}\n",
    "    metric2unit = {'P&L(bps)': 'bps', 'P&L($)': '$'}\n",
    "\n",
    "    # unjsonify metrics, and append columns\n",
    "    metrics_df = pd.DataFrame([json2row(json) for json in df['Metrics in NAV JSON']])\n",
    "    metrics_df.index = df.index\n",
    "\n",
    "    #cln2decimal_pts = {}\n",
    "    #colnames_to_sum = []\n",
    "    #display_columns = []\n",
    "    for (metric, period) in metrics2include:\n",
    "        unit = metric2unit[metric]\n",
    "        disp_name = metric2display_name[metric]\n",
    "        display_colname = disp_name + ' ' + period + '(' + unit + ')'\n",
    "        df[display_colname] = metrics_df[metric + '|' + period]\n",
    "        #if unit == '$':\n",
    "            #cln2decimal_pts[display_colname] = 0\n",
    "            #colnames_to_sum.append(display_colname)\n",
    "        #if unit == 'bps':\n",
    "            #cln2decimal_pts[display_colname] = 1\n",
    "            #colnames_to_sum.append(display_colname)\n",
    "        #if unit == '%':\n",
    "            #cln2decimal_pts[display_colname] = 2\n",
    "        #display_columns.append(display_colname)\n",
    "\n",
    "    del df['Metrics in NAV JSON']; del df['Metrics in NAV notes JSON'];\n",
    "    del df['Metrics in Bet JSON']; del df['Metrics in Bet notes JSON'];\n",
    "    del df['Analyst']\n",
    "\n",
    "    sleeve2code = {'Merger Arbitrage': 'M&A', 'Equity Special Situations': 'ESS',\n",
    "                   'Opportunistic' : 'OPP', 'Forwards':'FWD', 'Credit Opportunities':'CREDIT'}\n",
    "\n",
    "    df['Sleeve'] = df['Sleeve'].apply(lambda x: sleeve2code[x] if x in sleeve2code else x)\n",
    "    df = df[(~pd.isnull(df[' YTD($)']))]  # don't show null ytds. i.e. tradegroups closed before year started\n",
    "    df['Date'] = today.strftime('%Y-%m-%d')\n",
    "\n",
    "    base_cols = ['Date', 'Fund', 'Sleeve', 'TradeGroup', 'LongShort', 'InceptionDate', 'EndDate', 'Status']\n",
    "    bps_cols = [' ITD(bps)', ' YTD(bps)', ' QTD(bps)', ' MTD(bps)', ' 30D(bps)', ' 5D(bps)', ' 1D(bps)']  \n",
    "    dollar_cols = [' ITD($)', ' YTD($)', ' QTD($)', ' MTD($)', ' 30D($)', ' 5D($)', ' 1D($)']\n",
    "    bps_df = df[base_cols+bps_cols].sort_values(by=' YTD(bps)')\n",
    "    bps_df.rename(columns={' ITD(bps)': 'ITD(bps)', ' YTD(bps)': 'YTD(bps)', ' QTD(bps)': 'QTD(bps)',\n",
    "                           ' MTD(bps)': 'MTD(bps)', ' 30D(bps)': '30D(bps)', ' 5D(bps)': '5D(bps)',\n",
    "                           ' 1D(bps)': '1D(bps)'}, inplace=True)\n",
    "    dollar_df = df[base_cols+dollar_cols].sort_values(by=' YTD($)')\n",
    "    dollar_df.rename(columns={' ITD($)': 'ITD($)', ' YTD($)': 'YTD($)', ' QTD($)': 'QTD($)',\n",
    "                              ' MTD($)': 'MTD($)', ' 30D($)': '30D($)', ' 5D($)': '5D($)',\n",
    "                              ' 1D($)': '1D($)'}, inplace=True)\n",
    "\n",
    "    return bps_df, dollar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TradeGroup Attribution to Fund NAV Page\n",
    "x = get_tradegroups_attribution_to_fund_nav() \n",
    "#Produces two dataframes: one for bps and one for dollar\n",
    "unique_tradegroups = x[0]['TradeGroup'].unique()\n",
    "limit_to_tradegroups = list(unique_tradegroups)\n",
    "unique_funds = x[0]['Fund'].unique()\n",
    "limit_to_funds = list(unique_funds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_and_tradegroup_combos = x[0][[\"Fund\", \"TradeGroup\"]]\n",
    "fund_and_tradegroup_combos = fund_and_tradegroup_combos.reset_index()\n",
    "del fund_and_tradegroup_combos['index']\n",
    "fund_and_tradegroup_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCVH retrieval completed....\n"
     ]
    }
   ],
   "source": [
    "PCVH = get_position_calculated_values_history(limit_to_tradegroups=['ANDX - MPLX'], fund_code='LEV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>FundCode</th>\n",
       "      <th>TradeGroup</th>\n",
       "      <th>TradeGroup_Tradar_Name</th>\n",
       "      <th>Sleeve</th>\n",
       "      <th>Bucket</th>\n",
       "      <th>TradeGroupId</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>SecType</th>\n",
       "      <th>MarketCapCategory</th>\n",
       "      <th>...</th>\n",
       "      <th>Capital(%)</th>\n",
       "      <th>BaseCaseNavImpact</th>\n",
       "      <th>OutlierNavImpact</th>\n",
       "      <th>Qty</th>\n",
       "      <th>LongShort</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Fund_NAV</th>\n",
       "      <th>Equity_Risk_Exp</th>\n",
       "      <th>DealDuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>Merger Arbitrage</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>94900.0</td>\n",
       "      <td>ANDX US</td>\n",
       "      <td>EQ</td>\n",
       "      <td>Mid Cap</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5036</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.04000</td>\n",
       "      <td>2455.0</td>\n",
       "      <td>Long</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Oil, Gas &amp; Consumable Fuels</td>\n",
       "      <td>5691731.470000</td>\n",
       "      <td>84997.511812</td>\n",
       "      <td>0M-3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>Merger Arbitrage</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>94900.0</td>\n",
       "      <td>MPLX US</td>\n",
       "      <td>EQ</td>\n",
       "      <td>Large Cap</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-1.33000</td>\n",
       "      <td>-2786.0</td>\n",
       "      <td>Long</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Oil, Gas &amp; Consumable Fuels</td>\n",
       "      <td>5691731.470000</td>\n",
       "      <td>-85558.060000</td>\n",
       "      <td>0M-3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>Merger Arbitrage</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>94900.0</td>\n",
       "      <td>ANDX US</td>\n",
       "      <td>EQ</td>\n",
       "      <td>Mid Cap</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5390</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.02000</td>\n",
       "      <td>2455.0</td>\n",
       "      <td>Long</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Oil, Gas &amp; Consumable Fuels</td>\n",
       "      <td>5670723.470000</td>\n",
       "      <td>86368.368653</td>\n",
       "      <td>0M-3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>Merger Arbitrage</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>94900.0</td>\n",
       "      <td>MPLX US</td>\n",
       "      <td>EQ</td>\n",
       "      <td>Large Cap</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-1.31000</td>\n",
       "      <td>-2786.0</td>\n",
       "      <td>Long</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Oil, Gas &amp; Consumable Fuels</td>\n",
       "      <td>5670723.470000</td>\n",
       "      <td>-87313.240000</td>\n",
       "      <td>0M-3M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date FundCode   TradeGroup TradeGroup_Tradar_Name            Sleeve  \\\n",
       "0 2019-05-09      LEV  ANDX - MPLX            ANDX - MPLX  Merger Arbitrage   \n",
       "1 2019-05-09      LEV  ANDX - MPLX            ANDX - MPLX  Merger Arbitrage   \n",
       "2 2019-05-10      LEV  ANDX - MPLX            ANDX - MPLX  Merger Arbitrage   \n",
       "3 2019-05-10      LEV  ANDX - MPLX            ANDX - MPLX  Merger Arbitrage   \n",
       "\n",
       "      Bucket  TradeGroupId   Ticker SecType MarketCapCategory     ...       \\\n",
       "0  Optimized       94900.0  ANDX US      EQ           Mid Cap     ...        \n",
       "1  Optimized       94900.0  MPLX US      EQ         Large Cap     ...        \n",
       "2  Optimized       94900.0  ANDX US      EQ           Mid Cap     ...        \n",
       "3  Optimized       94900.0  MPLX US      EQ         Large Cap     ...        \n",
       "\n",
       "   Capital(%) BaseCaseNavImpact OutlierNavImpact     Qty LongShort  Sector  \\\n",
       "0      1.5036              0.45          1.04000  2455.0      Long  Energy   \n",
       "1         NaN             -0.68         -1.33000 -2786.0      Long  Energy   \n",
       "2      1.5390              0.42          1.02000  2455.0      Long  Energy   \n",
       "3         NaN             -0.65         -1.31000 -2786.0      Long  Energy   \n",
       "\n",
       "                      Industry        Fund_NAV  Equity_Risk_Exp DealDuration  \n",
       "0  Oil, Gas & Consumable Fuels  5691731.470000     84997.511812        0M-3M  \n",
       "1  Oil, Gas & Consumable Fuels  5691731.470000    -85558.060000        0M-3M  \n",
       "2  Oil, Gas & Consumable Fuels  5670723.470000     86368.368653        0M-3M  \n",
       "3  Oil, Gas & Consumable Fuels  5670723.470000    -87313.240000        0M-3M  \n",
       "\n",
       "[4 rows x 37 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCVH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPREADS_HISTORY_DF = get_spread_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TG_PNL_DF = get_tradegroups_pnl_cache(fundcode='LEV', tg='ANDX - MPLX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUND_NAV_DF = get_NAV_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0499999523163\n"
     ]
    }
   ],
   "source": [
    "SECURITIES_PNL_DF = get_securities_pnl_by_tradegroup_and_fund(limit_to_tradegroups=['ANDX - MPLX'],\n",
    "                                                              limit_to_funds=['LEV'], rollup_pnl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Fund</th>\n",
       "      <th>TradeGroup</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>SecType</th>\n",
       "      <th>Total P&amp;L</th>\n",
       "      <th>Cumulative Total P&amp;L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>ANDX US</td>\n",
       "      <td>Equity</td>\n",
       "      <td>302.2105</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>ANDX US</td>\n",
       "      <td>Equity</td>\n",
       "      <td>1693.9500</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>MPLX US</td>\n",
       "      <td>Equity</td>\n",
       "      <td>-499.6194</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>MPLX US</td>\n",
       "      <td>Equity</td>\n",
       "      <td>-1755.1800</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>USD</td>\n",
       "      <td>Currencies</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>USD</td>\n",
       "      <td>Currencies</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Fund   TradeGroup   Ticker     SecType  Total P&L  \\\n",
       "0 2019-05-09  LEV  ANDX - MPLX  ANDX US      Equity   302.2105   \n",
       "1 2019-05-10  LEV  ANDX - MPLX  ANDX US      Equity  1693.9500   \n",
       "2 2019-05-09  LEV  ANDX - MPLX  MPLX US      Equity  -499.6194   \n",
       "3 2019-05-10  LEV  ANDX - MPLX  MPLX US      Equity -1755.1800   \n",
       "4 2019-05-09  LEV  ANDX - MPLX      USD  Currencies     0.0000   \n",
       "5 2019-05-10  LEV  ANDX - MPLX      USD  Currencies     0.0000   \n",
       "\n",
       "  Cumulative Total P&L  \n",
       "0                 None  \n",
       "1                 None  \n",
       "2                 None  \n",
       "3                 None  \n",
       "4                 None  \n",
       "5                 None  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SECURITIES_PNL_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def get_current_tradegroup():\n",
    "#    query = \"SELECT `Date`, Fund, TradeGroup FROM \" + DB_NAME + \".tradegroup_attribution_to_fund_nav_dollar \" \\\n",
    "#            \"WHERE `Date` = '2018-05-23'\"\n",
    "#    \n",
    "#    res = wic_optimized_execute(query)\n",
    "#    cols=['Date', 'Fund', 'TradeGroup']\n",
    "#    return pd.DataFrame(list(res), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = get_current_tradegroup()\n",
    "#f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is best to fill in the history by fund as the securities_pnl query takes too long to do all funds at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_pnl_df(fund_code, SECURITIES_PNL_DF, TG_PNL_DF, PCVH, FUND_NAV_DF):\n",
    "    \n",
    "    start = time.time()\n",
    "    SECURITIES_PNL_DF['TradeGroup'] = SECURITIES_PNL_DF['TradeGroup'].apply(lambda x: x.upper())\n",
    "    TG_PNL_DF['TradeGroup'] = TG_PNL_DF['TradeGroup'].apply(lambda x: x.upper())\n",
    "    PCVH['TradeGroup'] = PCVH['TradeGroup'].apply(lambda x: x.upper())\n",
    "    \n",
    "    tradegroups = SECURITIES_PNL_DF['TradeGroup'].unique()\n",
    "    #limit_to_tradegroups = list(fund_tg_combos['TradeGroup'].unique())\n",
    "    #limit_to_funds = list(fund_tg_combos['Fund'].unique())\n",
    "    final_pnl_df = pd.DataFrame()\n",
    "    final_ticker_pnl_df = pd.DataFrame()\n",
    "    for i in range(0, len(tradegroups)):\n",
    "        bps_dollar_pnl_df = pd.DataFrame()\n",
    "        bps_dollar_ticker_pnl_df = pd.DataFrame()\n",
    "        tradar_tg_name = tradegroups[i]\n",
    "        print(tradar_tg_name)\n",
    "        fund = fund_code\n",
    "        \n",
    "        tg_pcvh = PCVH[(PCVH.TradeGroup == tradar_tg_name) & (PCVH.FundCode == fund)].copy()\n",
    "        fund_nav_df = FUND_NAV_DF[FUND_NAV_DF.FundCode == fund].copy()\n",
    "        securities_pnl_df = SECURITIES_PNL_DF[(SECURITIES_PNL_DF.TradeGroup == tradar_tg_name)].copy()\n",
    "        tg_pnl_df = TG_PNL_DF[(TG_PNL_DF.TradeGroup == tradar_tg_name) & (TG_PNL_DF.Fund == fund)].copy()\n",
    "\n",
    "        options_pnl_df = securities_pnl_df[securities_pnl_df['SecType'] ==\n",
    "                                           'Option'][['Date', 'Total P&L']].groupby('Date').sum().reset_index().copy()\n",
    "        options_pnl_df = options_pnl_df.iloc[np.trim_zeros(options_pnl_df['Total P&L']).index].copy()\n",
    "\n",
    "        if len(options_pnl_df) > 0:\n",
    "            options_pnl_df = options_pnl_df.rename(columns={'Total P&L': 'Options_PnL_Dollar'})\n",
    "            options_pnl_df['Fund'] = fund\n",
    "            options_pnl_df['TradeGroup'] = tradar_tg_name\n",
    "            options_pnl_df = pd.merge(options_pnl_df, fund_nav_df, how='inner', on=['Date'])\n",
    "            options_pnl_df['Shifted Capital'] = options_pnl_df['NAV'].shift(1)\n",
    "            if pd.isnull(options_pnl_df['Shifted Capital'].iloc[0]):\n",
    "                options_pnl_df.loc[0, 'Shifted Capital'] = options_pnl_df['NAV'].iloc[0]\n",
    "            options_pnl_df['Shifted Capital'] = options_pnl_df['Shifted Capital'].apply(lambda x: np.nan if x == 0 else x)\n",
    "            options_pnl_df['Shifted Forward-Filled Capital'] = options_pnl_df['Shifted Capital'].ffill()\n",
    "            options_pnl_df['Options_PnL_bps'] = 1e4*(options_pnl_df[\"Options_PnL_Dollar\"]/\n",
    "                                                     options_pnl_df[\"Shifted Forward-Filled Capital\"]).replace([np.inf,\n",
    "                                                                                                                -np.inf],\n",
    "                                                                                                               np.nan)\n",
    "            if bps_dollar_pnl_df.empty:\n",
    "                bps_dollar_pnl_df = bps_dollar_pnl_df.append(options_pnl_df[['Date', 'Fund', 'TradeGroup',\n",
    "                                                                         'Options_PnL_Dollar', 'Options_PnL_bps']], sort=True)\n",
    "            else:\n",
    "                bps_dollar_pnl_df = pd.merge(bps_dollar_pnl_df, options_pnl_df[['Date', 'Fund', 'TradeGroup',\n",
    "                                                                         'Options_PnL_Dollar', 'Options_PnL_bps']],\n",
    "                                             how='outer', on=['Date', 'Fund', 'TradeGroup'])\n",
    "\n",
    "        #P&L Breakdown by Ticker -- to be kept in a separate db\n",
    "        tg_securities = securities_pnl_df[securities_pnl_df['SecType'] != 'Option']['Ticker'].unique()\n",
    "        for ticker in tg_securities:\n",
    "            tkr_pnl_df = securities_pnl_df[securities_pnl_df['Ticker'] == ticker].copy()\n",
    "            tkr_pnl_df = tkr_pnl_df.loc[np.trim_zeros(tkr_pnl_df['Total P&L']).index].copy()\n",
    "            if len(tkr_pnl_df) == 0:\n",
    "                continue\n",
    "            tkr_pnl_df = tkr_pnl_df.rename(columns={'Total P&L': 'Ticker_PnL_Dollar'})\n",
    "            tkr_pnl_df['Fund'] = fund\n",
    "            tkr_pnl_df['TradeGroup'] = tradar_tg_name\n",
    "            tkr_pnl_df = pd.merge(tkr_pnl_df, fund_nav_df, how='inner', on=['Date'])\n",
    "            tkr_pnl_df['Shifted Capital'] = tkr_pnl_df['NAV'].shift(1)\n",
    "            if pd.isnull(tkr_pnl_df['Shifted Capital'].iloc[0]):\n",
    "                tkr_pnl_df.loc[0, 'Shifted Capital'] = tkr_pnl_df['NAV'].iloc[0]\n",
    "            tkr_pnl_df['Shifted Capital'] = tkr_pnl_df['Shifted Capital'].apply(lambda x: np.nan if x == 0 else x)\n",
    "            tkr_pnl_df['Shifted Forward-Filled Capital'] = tkr_pnl_df['Shifted Capital'].ffill()\n",
    "            tkr_pnl_df['Ticker_PnL_bps'] = 1e4*(tkr_pnl_df[\"Ticker_PnL_Dollar\"]/\n",
    "                                                     tkr_pnl_df[\"Shifted Forward-Filled Capital\"]).replace([np.inf,\n",
    "                                                                                                            -np.inf],\n",
    "                                                                                                            np.nan)  \n",
    "            bps_dollar_ticker_pnl_df = bps_dollar_ticker_pnl_df.append(tkr_pnl_df[['Date', 'Fund', 'TradeGroup',\n",
    "                                                                         'Ticker_PnL_Dollar', 'Ticker_PnL_bps', 'Ticker']])\n",
    "\n",
    "        final_ticker_pnl_df = final_ticker_pnl_df.append(bps_dollar_ticker_pnl_df, sort=True)\n",
    "\n",
    "        #Daily PnL  \n",
    "        daily_pnl_df = tg_pnl_df[['Date', 'Fund', 'TradeGroup', 'Total P&L']]\n",
    "        if len(daily_pnl_df) > 0:\n",
    "            daily_pnl_df = daily_pnl_df.rename(columns={'Total P&L': 'Daily_PnL_Dollar'})\n",
    "            daily_pnl_df['Fund'] = fund\n",
    "            daily_pnl_df['TradeGroup'] = tradar_tg_name\n",
    "            daily_pnl_df = pd.merge(daily_pnl_df, fund_nav_df, how='inner', on=['Date'])\n",
    "            daily_pnl_df['Shifted Capital'] = daily_pnl_df['NAV'].shift(1)\n",
    "            if pd.isnull(daily_pnl_df['Shifted Capital'].iloc[0]):\n",
    "                daily_pnl_df.loc[0, 'Shifted Capital'] = daily_pnl_df['NAV'].iloc[0]\n",
    "            daily_pnl_df['Shifted Capital'] = daily_pnl_df['Shifted Capital'].apply(lambda x: np.nan if x == 0 else x)\n",
    "            daily_pnl_df['Shifted Forward-Filled Capital'] = daily_pnl_df['Shifted Capital'].ffill()\n",
    "            daily_pnl_df['Daily_PnL_bps'] = 1e4*(daily_pnl_df[\"Daily_PnL_Dollar\"]/\n",
    "                                                     daily_pnl_df[\"Shifted Forward-Filled Capital\"]).replace([np.inf, -np.inf],\n",
    "                                                                                                             np.nan)  \n",
    "            if bps_dollar_pnl_df.empty:\n",
    "                bps_dollar_pnl_df = bps_dollar_pnl_df.append(daily_pnl_df[['Date', 'Fund', 'TradeGroup',\n",
    "                                                                         'Daily_PnL_Dollar', 'Daily_PnL_bps']], sort=True)\n",
    "            else:\n",
    "                bps_dollar_pnl_df = pd.merge(bps_dollar_pnl_df, daily_pnl_df[['Date', 'Fund', 'TradeGroup',\n",
    "                                                                         'Daily_PnL_Dollar', 'Daily_PnL_bps']], how='outer',\n",
    "                                             on=['Date', 'Fund', 'TradeGroup'])\n",
    "\n",
    "        cum_pnl = pd.DataFrame()\n",
    "        rolling_vol_df = pd.DataFrame()\n",
    "        if len(tg_pcvh) > 0:\n",
    "                tg_capital_df = mktval_df(tg_pcvh)\n",
    "                roc_df = pd.merge(tg_pnl_df, tg_capital_df[['Date', 'Bet GrossMktVal']], how='inner', on=['Date'])\n",
    "                if len(roc_df) > 1:\n",
    "                    roc_df['Shifted Capital'] = roc_df['Bet GrossMktVal'].shift(1)\n",
    "                    if pd.isnull(roc_df['Shifted Capital'].iloc[0]):\n",
    "                        roc_df.loc[0, 'Shifted Capital'] = roc_df['Bet GrossMktVal'].iloc[0]\n",
    "                    roc_df['Shifted Capital'] = roc_df['Shifted Capital'].apply(lambda x: np.nan if x == 0 else x)\n",
    "                    roc_df['Shifted Forward-Filled Capital'] = roc_df['Shifted Capital'].ffill()\n",
    "                    roc_df['PnL_Over_Cap_bps'] = 1e4*(roc_df[\"Total P&L\"]/\n",
    "                                               roc_df[\"Shifted Forward-Filled Capital\"]).replace([np.inf, -np.inf],\n",
    "                                                                                                 np.nan) \n",
    "\n",
    "                    #roc_df['Cumulative P&L (%)'] = roc_df['Cumulative P&L bps (ffiled)'].apply(lambda x: x/100.0)\n",
    "                    roc_df['Rolling_30D_PnL_Vol'] = math.sqrt(252)*(roc_df['PnL_Over_Cap_bps']/100.0).rolling(window=30).std()\n",
    "                    if len(roc_df['Rolling_30D_PnL_Vol'].dropna()) > 0:\n",
    "                        rolling_vol_df[['Date', 'Fund', 'TradeGroup', 'Rolling_30D_PnL_Vol']] = roc_df[\n",
    "                            [\"Date\", \"Fund\", \"TradeGroup\", \"Rolling_30D_PnL_Vol\"]].dropna()\n",
    "\n",
    "                        if bps_dollar_pnl_df.empty:\n",
    "                            bps_dollar_pnl_df = bps_dollar_pnl_df.append(rolling_vol_df[['Date', 'Fund', 'TradeGroup',\n",
    "                                                                                         'Rolling_30D_PnL_Vol']], sort=True)\n",
    "                        else:\n",
    "                            bps_dollar_pnl_df = bps_dollar_pnl_df.merge(rolling_vol_df[['Date', 'Fund',\n",
    "                                                                                        'TradeGroup',\n",
    "                                                                                        'Rolling_30D_PnL_Vol']],\n",
    "                                                                        how='outer', on=['Date', 'Fund', 'TradeGroup'])\n",
    "\n",
    "                    if bps_dollar_pnl_df.empty:\n",
    "                        bps_dollar_pnl_df = bps_dollar_pnl_df.append(roc_df[['Date', 'Fund', 'TradeGroup'\n",
    "                                                                         'PnL_Over_Cap_bps']], sort=True)\n",
    "                    else:\n",
    "                        bps_dollar_pnl_df = bps_dollar_pnl_df.merge(roc_df[['Date', 'Fund', 'TradeGroup', 'PnL_Over_Cap_bps']],\n",
    "                                                                    how='outer', on=['Date', 'Fund', 'TradeGroup'])\n",
    "        \n",
    "        final_pnl_df = final_pnl_df.append(bps_dollar_pnl_df)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "    return final_pnl_df, final_ticker_pnl_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANDX - MPLX\n",
      "0.149000167847\n"
     ]
    }
   ],
   "source": [
    "f = 'LEV'\n",
    "x = daily_pnl_df(f, SECURITIES_PNL_DF, TG_PNL_DF, PCVH, FUND_NAV_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Daily_PnL_Dollar</th>\n",
       "      <th>Daily_PnL_bps</th>\n",
       "      <th>Date</th>\n",
       "      <th>Fund</th>\n",
       "      <th>TradeGroup</th>\n",
       "      <th>PnL_Over_Cap_bps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-197.4089</td>\n",
       "      <td>-0.346835</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>-23.066827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Daily_PnL_Dollar  Daily_PnL_bps       Date Fund   TradeGroup  \\\n",
       "0         -197.4089      -0.346835 2019-05-09  LEV  ANDX - MPLX   \n",
       "\n",
       "   PnL_Over_Cap_bps  \n",
       "0        -23.066827  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = x[0]\n",
    "a = a[a.Date == '2019-05-09']\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Fund</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Ticker_PnL_Dollar</th>\n",
       "      <th>Ticker_PnL_bps</th>\n",
       "      <th>TradeGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX US</td>\n",
       "      <td>302.2105</td>\n",
       "      <td>0.530964</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>LEV</td>\n",
       "      <td>MPLX US</td>\n",
       "      <td>-499.6194</td>\n",
       "      <td>-0.877799</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Fund   Ticker  Ticker_PnL_Dollar  Ticker_PnL_bps   TradeGroup\n",
       "0 2019-05-09  LEV  ANDX US           302.2105        0.530964  ANDX - MPLX\n",
       "0 2019-05-09  LEV  MPLX US          -499.6194       -0.877799  ANDX - MPLX"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = x[1]\n",
    "b = b[b.Date == '2019-05-09']\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sqlalchemy import create_engine\n",
    "#WIC_DB_HOST = 'wic-risk-database.cwi02trt7ww1.us-east-1.rds.amazonaws.com'\n",
    "#DB_USER = 'root'\n",
    "#DB_PASSWORD = 'waterislandcapital'\n",
    "#DB_NAME = 'dev_wic_db'\n",
    "#engine = create_engine(\"mysql://\" + DB_USER + \":\" + DB_PASSWORD + \"@\" + WIC_DB_HOST + \"/dev_wic_db\")\n",
    "#con = engine.connect()\n",
    "#b.to_sql(con=con, schema='dev_wic_db', name='ticker_pnl_breakdown', if_exists='append', chunksize=1000, index=False)\n",
    "#con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv('C:/Users/aduprey/Desktop/TradeGroups_Data/ARB_pnl_overall.csv')\n",
    "b.to_csv('C:/Users/aduprey/Desktop/TradeGroups_Data/ARB_pnl_ticker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exposure_spreads_nav_df(fund_c, PCVH, FUND_NAV_DF, SPREAD_HISTORY_DF):\n",
    "    start = time.time()\n",
    "    PCVH['TradeGroup'] = PCVH['TradeGroup'].apply(lambda x: x.upper())\n",
    "    SPREAD_HISTORY_DF['TradeGroup'] = SPREAD_HISTORY_DF['TradeGroup'].apply(lambda x: x.upper())\n",
    "    overall_df = pd.DataFrame()\n",
    "    fund = fund_c\n",
    "    PCVH = PCVH[PCVH.FundCode == fund]\n",
    "    tg_combos = PCVH['TradeGroup'].unique()\n",
    "    for i in range(0, len(tg_combos)):\n",
    "        overall_exp_df = pd.DataFrame()\n",
    "        tradar_tg_name = tg_combos[i]\n",
    "        #fund = fund_tg_combos['Fund'][i]\n",
    "\n",
    "        tg_pcvh = PCVH[(PCVH.TradeGroup == tradar_tg_name)].copy()\n",
    "        fund_nav_df = FUND_NAV_DF[FUND_NAV_DF.FundCode == fund].copy()\n",
    "        spreads_history_df = SPREADS_HISTORY_DF[SPREADS_HISTORY_DF.TradeGroup_TradarName == tradar_tg_name].copy()\n",
    "        \n",
    "        # Capital AS (%) OF NAV TIME SERIES #\n",
    "        cap_df = pd.DataFrame()\n",
    "        capital_df = tg_pcvh[tg_pcvh['AlphaHedge']\n",
    "                             .isin(['Alpha',\n",
    "                                    'Alpha Hedge'])][['Date',\n",
    "                                                      'NetMktVal']].groupby('Date').agg(lambda x: sum(abs(x))).reset_index()\n",
    "        if len(capital_df) > 0:\n",
    "            capital_df = pd.merge(capital_df, fund_nav_df, how='inner', on=['Date'])\n",
    "            capital_df['CapitalAsPctOfNAV'] = 100.0*(capital_df['NetMktVal'].astype(float)\n",
    "                                                 /capital_df['NAV'].astype(float))\n",
    "    \n",
    "            cap_df['Date'] = capital_df['Date']\n",
    "            cap_df['Capital_Percent_of_NAV'] = capital_df['CapitalAsPctOfNAV']\n",
    "            cap_df['Fund'] = fund\n",
    "            cap_df['TradeGroup'] = tradar_tg_name\n",
    "            \n",
    "            if overall_exp_df.empty:\n",
    "                overall_exp_df = overall_exp_df.append(cap_df)\n",
    "            else:\n",
    "                overall_exp_df = overall_exp_df.merge(cap_df, how='outer', on=['Date', 'Fund', 'TradeGroup'])\n",
    "        \n",
    "        # NETEXP (% OF NAV) #\n",
    "        net_exp_df = pd.DataFrame()\n",
    "        tot_net_exp_df = tg_pcvh[['Date', 'Exposure_Net']].groupby('Date').sum().reset_index()\n",
    "        tot_net_exp_df = tot_net_exp_df.rename(columns={'Exposure_Net':'Total Exposure'}).sort_values(by='Date')\n",
    "        tot_net_exp_df = pd.merge(tot_net_exp_df, fund_nav_df, how='inner', on=['Date'])\n",
    "        tot_net_exp_df['NetExpAsPctOfNAV'] = 100.0*(tot_net_exp_df['Total Exposure'].astype(float)\n",
    "                                                    /tot_net_exp_df['NAV'].astype(float))\n",
    "        if len(tot_net_exp_df) > 0:\n",
    "            net_exp_df['Date'] = tot_net_exp_df['Date']\n",
    "            net_exp_df['NetExp_Percent_of_NAV'] = tot_net_exp_df['NetExpAsPctOfNAV']\n",
    "            net_exp_df['Fund'] = fund\n",
    "            net_exp_df['TradeGroup'] = tradar_tg_name\n",
    "            \n",
    "            if overall_exp_df.empty:\n",
    "                overall_exp_df = overall_exp_df.append(net_exp_df)\n",
    "            else:\n",
    "                overall_exp_df = overall_exp_df.merge(net_exp_df, how='outer', on=['Date', 'Fund', 'TradeGroup'])\n",
    "\n",
    "        # GROSSEXP (% OF NAV) #\n",
    "        gross_exp_df = pd.DataFrame()\n",
    "        tot_gross_exp_df = tg_pcvh[['Date', 'Exposure_Net']].groupby('Date').agg(lambda x: sum(abs(x))).reset_index()\n",
    "        tot_gross_exp_df = tot_gross_exp_df.rename(columns={'Exposure_Net':\n",
    "                                                            'Total Gross Exposure'}).sort_values(by='Date')\n",
    "        tot_gross_exp_df = pd.merge(tot_gross_exp_df, fund_nav_df, how='inner', on=['Date'])\n",
    "        tot_gross_exp_df['GrossExpAsPctOfNAV'] = 100.0*(tot_gross_exp_df['Total Gross Exposure'].astype(float)\n",
    "                                                        /tot_gross_exp_df['NAV'].astype(float))\n",
    "        if len(tot_gross_exp_df) > 0:\n",
    "            gross_exp_df['Date'] = tot_gross_exp_df['Date']\n",
    "            gross_exp_df['GrossExp_Percent_of_NAV'] = tot_gross_exp_df['GrossExpAsPctOfNAV']\n",
    "            gross_exp_df['Fund'] = fund\n",
    "            gross_exp_df['TradeGroup'] = tradar_tg_name\n",
    "            \n",
    "            if overall_exp_df.empty:\n",
    "                overall_exp_df = overall_exp_df.append(gross_exp_df)\n",
    "            else:\n",
    "                overall_exp_df = overall_exp_df.merge(gross_exp_df, how='outer', on=['Date', 'Fund', 'TradeGroup'])\n",
    "           \n",
    "        hedge_exp_df = pd.DataFrame()\n",
    "        if len(tg_pcvh) > 0:\n",
    "            alpha_net_exp = tg_pcvh[tg_pcvh['AlphaHedge'] ==\n",
    "                                    'Alpha'][['Date', 'Exposure_Net']].groupby('Date').sum().reset_index()\n",
    "            alphahedge_net_exp = tg_pcvh[tg_pcvh['AlphaHedge'] ==\n",
    "                                         'Alpha Hedge'][['Date', 'Exposure_Net']].groupby('Date').sum().reset_index()\n",
    "            hedge_net_exp = tg_pcvh[tg_pcvh['AlphaHedge'] ==\n",
    "                                    'Hedge'][['Date', 'Exposure_Net']].groupby('Date').sum().reset_index()\n",
    "\n",
    "            if len(alpha_net_exp) > 0:\n",
    "                alpha_net_exp_df = pd.DataFrame()\n",
    "                alpha_net_exp = pd.merge(alpha_net_exp, fund_nav_df, how='inner', on=['Date'])\n",
    "                alpha_net_exp['Exposure_Net'] = 100.0*(alpha_net_exp['Exposure_Net'].astype(float)\n",
    "                                                       /alpha_net_exp['NAV'].astype(float))\n",
    "                alpha_net_exp_df['Date'] = alpha_net_exp['Date']\n",
    "                alpha_net_exp_df['Alpha_Exposure'] = alpha_net_exp['Exposure_Net']\n",
    "                alpha_net_exp_df['Fund'] = fund\n",
    "                alpha_net_exp_df['TradeGroup'] = tradar_tg_name\n",
    "                \n",
    "                if overall_exp_df.empty:\n",
    "                    overall_exp_df = overall_exp_df.append(alpha_net_exp_df)\n",
    "                else:\n",
    "                    overall_exp_df = overall_exp_df.merge(alpha_net_exp_df, how='outer', on=['Date', 'Fund', 'TradeGroup'])\n",
    "            \n",
    "            if len(alphahedge_net_exp) > 0:\n",
    "                alphahedge_net_exp_df = pd.DataFrame()\n",
    "                alphahedge_net_exp = pd.merge(alphahedge_net_exp, fund_nav_df, how='inner', on=['Date'])\n",
    "                alphahedge_net_exp['Exposure_Net'] = 100.0*(alphahedge_net_exp['Exposure_Net'].astype(float)\n",
    "                                                            /alphahedge_net_exp['NAV'].astype(float))\n",
    "                alphahedge_net_exp_df['Date'] = alphahedge_net_exp['Date']\n",
    "                alphahedge_net_exp_df['AlphaHedge_Exposure'] = alphahedge_net_exp['Exposure_Net']\n",
    "                alphahedge_net_exp_df['Fund'] = fund\n",
    "                alphahedge_net_exp_df['TradeGroup'] = tradar_tg_name\n",
    "            \n",
    "                if overall_exp_df.empty:\n",
    "                    overall_exp_df = overall_exp_df.append(alphahedge_net_exp_df)\n",
    "                else:\n",
    "                    overall_exp_df = overall_exp_df.merge(alphahedge_net_exp_df, how='outer', on=['Date', 'Fund', 'TradeGroup'])\n",
    "\n",
    "            if len(hedge_net_exp) > 0:\n",
    "                hedge_net_exp_df = pd.DataFrame()\n",
    "                hedge_net_exp = pd.merge(hedge_net_exp, fund_nav_df, how='inner', on=['Date'])\n",
    "                hedge_net_exp['Exposure_Net'] = 100.0*(hedge_net_exp['Exposure_Net'].astype(float)\n",
    "                                                       /hedge_net_exp['NAV'].astype(float))\n",
    "                hedge_net_exp_df['Date'] = hedge_net_exp['Date']\n",
    "                hedge_net_exp_df['Hedge_Exposure'] = hedge_net_exp['Exposure_Net']\n",
    "                hedge_net_exp_df['Fund'] = fund\n",
    "                hedge_net_exp_df['TradeGroup'] = tradar_tg_name\n",
    "                \n",
    "                if overall_exp_df.empty:\n",
    "                    overall_exp_df = overall_exp_df.append(hedge_net_exp_df)\n",
    "                else:\n",
    "                    overall_exp_df = overall_exp_df.merge(hedge_net_exp_df, how='outer', on=['Date', 'Fund', 'TradeGroup'])\n",
    "        \n",
    "        #SPREAD AS PERCENT#\n",
    "        spread = pd.DataFrame()\n",
    "        if tradar_tg_name in spreads_history_df['TradeGroup_TradarName'].unique():\n",
    "            spreads_ts_df = spreads_history_df[spreads_history_df['TradeGroup_TradarName'] ==\n",
    "                                               tradar_tg_name][['Date', 'Spread(%)']].sort_values(by='Date')\n",
    "            spreads_ts_df = spreads_ts_df.rename(columns={'Spread(%)':'SpreadAsPct'}).sort_values(by='Date')\n",
    "            spreads_ts_df['SpreadAsPct'] = spreads_ts_df['SpreadAsPct'].astype(float)\n",
    "            \n",
    "            spread['Date'] = spreads_ts_df['Date']\n",
    "            spread['Spread_as_Percent'] = spreads_ts_df['SpreadAsPct']\n",
    "            spread['Fund'] = fund\n",
    "            spread['TradeGroup'] = tradar_tg_name\n",
    "            \n",
    "            if overall_exp_df.empty:\n",
    "                overall_exp_df = overall_exp_df.append(spread)\n",
    "            else:\n",
    "                overall_exp_df = overall_exp_df.merge(spread, how='outer', on=['Date', 'Fund', 'TradeGroup'])\n",
    "                \n",
    "        overall_df = overall_df.append(overall_exp_df)  \n",
    "    \n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    return overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.111999988556\n"
     ]
    }
   ],
   "source": [
    "overall_df = get_exposure_spreads_nav_df('LEV', PCVH, FUND_NAV_DF, SPREADS_HISTORY_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Capital_Percent_of_NAV</th>\n",
       "      <th>Fund</th>\n",
       "      <th>TradeGroup</th>\n",
       "      <th>NetExp_Percent_of_NAV</th>\n",
       "      <th>GrossExp_Percent_of_NAV</th>\n",
       "      <th>Alpha_Exposure</th>\n",
       "      <th>Hedge_Exposure</th>\n",
       "      <th>Spread_as_Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>1.503607</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>3.006807</td>\n",
       "      <td>1.503607</td>\n",
       "      <td>-1.503199</td>\n",
       "      <td>0.670177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>1.503607</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>3.006807</td>\n",
       "      <td>1.503607</td>\n",
       "      <td>-1.503199</td>\n",
       "      <td>1.044904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>1.539050</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>-0.000670</td>\n",
       "      <td>3.078769</td>\n",
       "      <td>1.539050</td>\n",
       "      <td>-1.539720</td>\n",
       "      <td>1.097250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LEV</td>\n",
       "      <td>ANDX - MPLX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.794764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Capital_Percent_of_NAV Fund   TradeGroup  NetExp_Percent_of_NAV  \\\n",
       "0 2019-05-09                1.503607  LEV  ANDX - MPLX               0.000408   \n",
       "1 2019-05-09                1.503607  LEV  ANDX - MPLX               0.000408   \n",
       "2 2019-05-10                1.539050  LEV  ANDX - MPLX              -0.000670   \n",
       "3 2019-05-08                     NaN  LEV  ANDX - MPLX                    NaN   \n",
       "\n",
       "   GrossExp_Percent_of_NAV  Alpha_Exposure  Hedge_Exposure  Spread_as_Percent  \n",
       "0                 3.006807        1.503607       -1.503199           0.670177  \n",
       "1                 3.006807        1.503607       -1.503199           1.044904  \n",
       "2                 3.078769        1.539050       -1.539720           1.097250  \n",
       "3                      NaN             NaN             NaN          -6.794764  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
